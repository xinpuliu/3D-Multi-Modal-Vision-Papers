# 3D-Multi-Modal-Vision-Papers

The Papers about 3D Vision of Multi Modals and Sensors.

---

## Datasets and Surveys

[1]【Dataset】《nuScenes: A multimodal dataset for autonomous driving》[PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Caesar_nuScenes_A_Multimodal_Dataset_for_Autonomous_Driving_CVPR_2020_paper.pdf) [Website](https://www.nuscenes.org/)

[2]【Dataset】《Scalability in Perception for Autonomous Driving: Waymo Open Dataset》[PDF](https://arxiv.org/pdf/1912.04838v7.pdf) [Website](https://waymo.com/open/)

[3]【Dataset】《Vision meets robotics: The KITTI dataset》[PDF](https://journals.sagepub.com/doi/epub/10.1177/0278364913491297) [Website](https://www.cvlibs.net/datasets/kitti/)

[4]【Survey】《Deep Multi-modal Object Detection and Semantic Segmentation for Autonomous Driving: Datasets, Methods, and Challenges》[PDF](https://ieeexplore.ieee.org/document/9000872) 

[5]【Survey】《Multi-Modal 3D Object Detection in Autonomous Driving: a Survey》[PDF](https://arxiv.org/pdf/2106.12735.pdf) 

[6]【Survey】《Multi-modal Sensor Fusion for Auto Driving Perception: A Survey》[PDF](https://www.researchgate.net/publication/358422913_Multi-modal_Sensor_Fusion_for_Auto_Driving_Perception_A_Survey/fulltext/6201e10a7047cd22c3541b56/Multi-modal-Sensor-Fusion-for-Auto-Driving-Perception-A-Survey.pdf) 

---

## CVPR 2022

[1] 【LiDAR+**Radar**】《Modality-Agnostic Learning for Radar-Lidar Fusion in Vehicle Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Modality-Agnostic_Learning_for_Radar-Lidar_Fusion_in_Vehicle_Detection_CVPR_2022_paper.pdf) 

[2] 【**Infrared**+Camera】《Target-Aware  Dual Adversarial Learning and a Multi-Scenario Multi-Modality Benchmark  To Fuse Infrared and Visible for Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/html/Liu_Target-Aware_Dual_Adversarial_Learning_and_a_Multi-Scenario_Multi-Modality_Benchmark_To_CVPR_2022_paper.html) [CODE](https://github.com/JinyuanLiu-CV/TarDAL)

[3] 【LiDAR+Camera】《MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation》[PDF](https://openaccess.thecvf.com/content/CVPR2022/html/Shin_MM-TTA_Multi-Modal_Test-Time_Adaptation_for_3D_Semantic_Segmentation_CVPR_2022_paper.html)

[4]【LiDAR+Camera】《CAT-Det: Contrastively Augmented Transformer for Multi-Modal 3D Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_CAT-Det_Contrastively_Augmented_Transformer_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf)

[5]【LiDAR+Camera】《DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_DeepFusion_Lidar-Camera_Deep_Fusion_for_Multi-Modal_3D_Object_Detection_CVPR_2022_paper.pdf) 

[6]【LiDAR+Camera】《Boosting 3D Object Detection by Simulating Multimodality on Point Clouds》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_Boosting_3D_Object_Detection_by_Simulating_Multimodality_on_Point_Clouds_CVPR_2022_paper.pdf)

[7]【LiDAR+Camera】《Voxel Field Fusion for 3D Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Voxel_Field_Fusion_for_3D_Object_Detection_CVPR_2022_paper.pdf) [CODE](https://github.com/dvlab-research/VFF)

[8]【LiDAR+Camera】《LIFT: Learning 4D LiDAR Image Fusion Transformer for 3D Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Zeng_LIFT_Learning_4D_LiDAR_Image_Fusion_Transformer_for_3D_Object_CVPR_2022_paper.pdf)

[9]【LiDAR+Camera】《Multimodal Token Fusion for Vision Transformers》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Multimodal_Token_Fusion_for_Vision_Transformers_CVPR_2022_paper.pdf) [CODE](https://github.com/yikaiw/TokenFusion)

[10]【LiDAR+Camera】《TransFusion: Robust LiDAR-Camera Fusion for 3D Object Detection with Transformers》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Bai_TransFusion_Robust_LiDAR-Camera_Fusion_for_3D_Object_Detection_With_Transformers_CVPR_2022_paper.pdf)

[11]【LiDAR+Camera】《Sparse Fuse Dense: Towards High Quality 3D Detection with Depth Completion》[PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wu_Sparse_Fuse_Dense_Towards_High_Quality_3D_Detection_With_Depth_CVPR_2022_paper.pdf) [CODE](https://github.com/LittlePey/SFD)

## Others 2022

[1] (T-PAMI)【LiDAR+Camera】《TransFuser: Imitation with Transformer-Based Sensor Fusion for Autonomous Driving》[PDF](https://arxiv.org/abs/2205.15997) [CODE](https://github.com/autonomousvision/transfuser)

[2] (arXiv)【LiDAR+Camera】《BEVFusion: A Simple and Robust LiDAR-Camera Fusion Framework》[PDF](https://arxiv.org/pdf/2205.13790.pdf) [CODE](https://github.com/ADLab-AutoDrive/BEVFusion)

[3] (arXiv)【LiDAR+Camera】《FUTR3D: A Unified Sensor Fusion Framework for 3D Detection》[PDF](https://arxiv.org/pdf/2203.10642v1.pdf) [CODE](https://github.com/Tsinghua-MARS-Lab/futr3d)

[4] (arXiv)【LiDAR+Camera】《DeepInteraction: 3D Object Detection via Modality Interaction》[PDF](https://arxiv.org/pdf/2208.11112.pdf) [CODE](https://github.com/fudan-zvg/DeepInteraction)

---

## CVPR 2021

[1]【LiDAR+Camera】《Multi-Modal Fusion Transformer for End-to-End Autonomous Driving》[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.pdf) [CODE](https://github.com/autonomousvision/transfuser)

[2]【LiDAR+Camera】《PointAugmenting: Cross-Modal Augmentation for 3D Object Detection》[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.pdf) [CODE](https://github.com/VISION-SJTU/PointAugmenting)

[3] 【LiDAR+**Radar**】《Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals》[PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.pdf) [CODE](https://github.com/qiank10/MVDNet)

## ICCV 2021

[1]【LiDAR+Camera】《Sparse-to-dense Feature Matching: Intra and Inter domain Cross-modal Learning in Domain Adaptation for 3D Semantic Segmentation》[PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Peng_Sparse-to-Dense_Feature_Matching_Intra_and_Inter_Domain_Cross-Modal_Learning_in_ICCV_2021_paper.pdf) [CODE](https://github.com/leolyj/DsCML)

[2]【**Radar**+Camera】《Robust Small Object Detection on the Water Surface through Fusion of Camera and Millimeter Wave Radar》[PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Cheng_Robust_Small_Object_Detection_on_the_Water_Surface_Through_Fusion_ICCV_2021_paper.pdf) 

[3]【LiDAR+Camera】《Perception-Aware Multi-Sensor Fusion for 3D LiDAR Semantic Segmentation》[PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhuang_Perception-Aware_Multi-Sensor_Fusion_for_3D_LiDAR_Semantic_Segmentation_ICCV_2021_paper.pdf) [CODE](https://github.com/ICEORY/PMF)

[4]【**Radar**+Camera】《Full-Velocity Radar Returns by Radar-Camera Fusion》[PDF](https://openaccess.thecvf.com/content/ICCV2021/papers/Long_Full-Velocity_Radar_Returns_by_Radar-Camera_Fusion_ICCV_2021_paper.pdf) 

---

## CVPR 2020

[1]【LiDAR+Camera】《Seeing Through Fog Without Seeing Fog: Deep Multimodal Sensor Fusion in Unseen Adverse Weather》[PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Bijelic_Seeing_Through_Fog_Without_Seeing_Fog_Deep_Multimodal_Sensor_Fusion_CVPR_2020_paper.pdf)
